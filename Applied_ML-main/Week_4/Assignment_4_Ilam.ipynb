{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "colab": {
      "name": "Assignment_4_Ilam.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ns1r37oEmco"
      },
      "source": [
        "![tud_logo.jpg](attachment:tud_logo.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbn6oFs9Emc0"
      },
      "source": [
        "# Assignment 4 - ML Ethical and Societal perspective\n",
        "Week 4 - CS4305TU Applied Machine Learning <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TORlcXDOEmc2"
      },
      "source": [
        "By <b> Nadia Metoui </b> and <b> Ibo van de Poel </b><br>\n",
        "Faculty of Technology, Policy, and Management (TPM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcdW9QeMEmc3"
      },
      "source": [
        "***Submission Instructions***\n",
        " - Answer the questions (code or text) in this Notebook \n",
        " - Rename the Notebook by adding your group number\n",
        " - Send the your answers both in ipynb and HTML format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFai2UCqEmc4"
      },
      "source": [
        "<H2>Part I: Socio-technical abstraction of an ML-based system</H2>\n",
        "<i>LO-1: Identify and analyse ethical issues related to ML.<i><br>\n",
        "<i>LO-2: Discuss machine learning fairness in the broader context of sociotechnical systems.</i>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEoX6HOhEmc4"
      },
      "source": [
        "Q1: Analyse and discuss the potential harmes of an ML-based Recommendation System using the Taxonomy and Model of Milan et <i>al.</i> (2020).\n",
        "To help with your analysis we provide 3 case studies you can find in Brightspace\n",
        "- Tiktok recommendation systems (See Case Study 1)\n",
        "- Youtube recommendation systems (See Case Study 2)\n",
        "- Tinder recommendation systems (See Case Study 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTIVr-47Emc5"
      },
      "source": [
        "Choose <b>one of the  Case Studies</b> above and answer the following questions based on your knowledge of the platform and the information you read on the case study:\n",
        "- a) Briefly summarise, what seems to be the ethical/social issue tackled in the use case you selected. \n",
        "- b) Who are the stakeholdes in this case? Name and describe at lease one stakeholdes from each category? \n",
        "- c) Briefly explain what are the intrests of each stakeholde and value they derive from using the recommendation system.\n",
        "- d) Briefly explain what are the potential harmes for each stakeholde and how are they impacting them?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmcvaHmrEmc6"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "<b>Tip:</b> Consider all stakholders depicted in the figure below. Use the categorization of (Milano 2020).<br>\n",
        "The full paper as well as a cheatsheet can be found in Brightspace.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9qpo6y_Emc8"
      },
      "source": [
        "![milano_model-2.png](attachment:milano_model-2.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K9BSyKUEmdA"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "<b>Types of Harm</b>\n",
        "- <u>on Utility</u>: Utility is the value each party is expecting to derive from using a the ML-based system. The impact or harm to Utility can be assessed using quantifiable metrics (e.g., time, money)\n",
        "- <u>on Rights</u>: legal, social, or ethical entitlements (e.g., privacy autonomy, equality)  The impact or harm to Ritghts is very hard to quantify.\n",
        "\n",
        "<br>\n",
        "\n",
        "<b>Types of Impacts</b>\n",
        "- <u>Immediate harm</u>: the recommendation or the ML-based system has an immediate and direct negative impact e.g., errors (incorrect outputs), out of context results (inappropriate outputs), opacity (uninterpretabel output).\n",
        "- <u>Exposure to Risk</u>: the recommendation or the ML-based system exposes the Stakeholder(s) to latent or potential negative impacts. Even if these impacts do not materialize, exposure to such risks is considered unethical.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUuJtUYOEmdC"
      },
      "source": [
        "-  Write your answers here you are free to add other cells if needed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lErAsG4KEmdC"
      },
      "source": [
        "<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBz5_vdgEmdD"
      },
      "source": [
        "<H2> Part II. Detecting and Mitigating bias*.</H2>\n",
        "<i>LO-3: Apply state-of-the-art debiasing approaches to identify and mitigate risks of biases in your ML-based system.</i><br>\n",
        "<i>LO-4. Compare different implementations of fairness metrics and unfairness mitigation approaches.  \n",
        "</i>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQWOPLX2EmdE"
      },
      "source": [
        "*Acknowledgement: Part II of this assignment is largely based on the code developed by <i><b>Agathe Balayn</b></i> and <i><b>Seda Gürses</b></i>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvH_HfquEmdE"
      },
      "source": [
        "In this part of the assignment, you will be exploring a use case where a Bank wants to develop an ML-based ADM (automate decision system) to decide whether to <b>grant</b> or <b>not to grant</b> a loan to a given applicant. To do so the Bank uses historical data containing multiple application records, characterized by information about the loan applicants (e.g., age, gender, personal situation) and information about the loan (e.g., amount, duration, purpose). Each application is labeled <i> good credit </i> if the loan had been reimbursed or <i>bad credit</i> if the loan has not been reimbursed or if there where several issues with the reimbursement.\n",
        "\n",
        "To simulate this scenario we will build a classifier to disinguich between good and bad loans (or credits). We will train the classifier using the <i><b>German credit data</b></i> (you can information about the dataset and its attributes here: (https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.doc).<br>\n",
        "And you can download the dataset here:\n",
        "https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data<br>\n",
        "\n",
        "\n",
        "You will be requested to take a closer look at the data and identify biases. We will use some tools form <i><b>AIF360 toolkit</b></i><br>(https://aif360.mybluemix.net/) a toolkit developed by IBM to detect and mitigate \"bias\" and \"unfairness\".\n",
        "\n",
        "Steps of Part II\n",
        "- Step 1: Set-up (Provided)\n",
        "- Step 2: Explore and familiarize with the dataset\n",
        "- Step 3: Pre-processing Biases: Protected attributes, proxies, data representation and skews  \n",
        "- Step 4: In-processing Biases: Identify and Mitigate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yxPn80rEmdF"
      },
      "source": [
        "<H3>Setp 2: Set-up</H3>\n",
        "\n",
        "You first need to install the required libraries for this part.  The main libraries are the `aif360`,  `lime`, and`sklearn` ones. We also recommend using `numpy` and `pandas` to easily manipulate and explore the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpfVHvw_EmdG"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\">\n",
        "<b>Note:</b> Uncomment and run the next cell if you have not previously installed the libraries.\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pdaym1yHEmdG"
      },
      "source": [
        "<b>Installing required libraries</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Z8NzkazEmdH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cb50e50-f126-48ff-e34d-147efdfc5360"
      },
      "source": [
        "!pip install aif360\n",
        "!pip install fairlearn\n",
        "!pip install tensorflow\n",
        "!pip install lime"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting aif360\n",
            "  Downloading aif360-0.4.0-py3-none-any.whl (175 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▉                              | 10 kB 23.6 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 40 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 51 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 61 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 71 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 81 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 92 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 143 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 153 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 163 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 174 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 175 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from aif360) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from aif360) (3.2.2)\n",
            "Requirement already satisfied: scipy<1.6.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from aif360) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.7/dist-packages (from aif360) (0.22.2.post1)\n",
            "Collecting tempeh\n",
            "  Downloading tempeh-0.1.12-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from aif360) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->aif360) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->aif360) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->aif360) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->aif360) (1.0.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aif360) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aif360) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aif360) (1.3.2)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from tempeh->aif360) (3.6.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from tempeh->aif360) (2.23.0)\n",
            "Collecting memory-profiler\n",
            "  Downloading memory_profiler-0.58.0.tar.gz (36 kB)\n",
            "Collecting shap\n",
            "  Downloading shap-0.39.0.tar.gz (356 kB)\n",
            "\u001b[K     |████████████████████████████████| 356 kB 46.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from memory-profiler->tempeh->aif360) (5.4.8)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (1.4.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (0.7.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (21.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (57.4.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (8.9.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (1.10.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->tempeh->aif360) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->tempeh->aif360) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->tempeh->aif360) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->tempeh->aif360) (1.24.3)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap->tempeh->aif360) (4.62.2)\n",
            "Collecting slicer==0.0.7\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap->tempeh->aif360) (0.51.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap->tempeh->aif360) (1.3.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->shap->tempeh->aif360) (0.34.0)\n",
            "Building wheels for collected packages: memory-profiler, shap\n",
            "  Building wheel for memory-profiler (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for memory-profiler: filename=memory_profiler-0.58.0-py3-none-any.whl size=30190 sha256=6886c8eb3e529b69e25e55114a105018af0d14f5672c4fec9771ac7b26b2a524\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/19/d5/8cad06661aec65a04a0d6785b1a5ad035cb645b1772a4a0882\n",
            "  Building wheel for shap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for shap: filename=shap-0.39.0-cp37-cp37m-linux_x86_64.whl size=491638 sha256=9b5837f45386781a3aec6b42402ca658f3c7955a76ffd4d6b2e0d715da435302\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/25/8f/6ae5df62c32651cd719e972e738a8aaa4a87414c4d2b14c9c0\n",
            "Successfully built memory-profiler shap\n",
            "Installing collected packages: slicer, shap, memory-profiler, tempeh, aif360\n",
            "Successfully installed aif360-0.4.0 memory-profiler-0.58.0 shap-0.39.0 slicer-0.0.7 tempeh-0.1.12\n",
            "Collecting fairlearn\n",
            "  Downloading fairlearn-0.7.0-py3-none-any.whl (177 kB)\n",
            "\u001b[K     |████████████████████████████████| 177 kB 6.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas>=0.25.1 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (1.1.5)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (1.4.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.1->fairlearn) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.1->fairlearn) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.25.1->fairlearn) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->fairlearn) (1.0.1)\n",
            "Installing collected packages: fairlearn\n",
            "Successfully installed fairlearn-0.7.0\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.6.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.6.0)\n",
            "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.6.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.40.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.6.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (5.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (3.3.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.5.0)\n",
            "Collecting lime\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[K     |████████████████████████████████| 275 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from lime) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lime) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lime) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from lime) (4.62.2)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from lime) (0.22.2.post1)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.7/dist-packages (from lime) (0.16.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (2.6.3)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (7.1.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (1.1.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->lime) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->lime) (1.0.1)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283857 sha256=a9e1ece41213c1ea327fbc8d25294fe12092ae60d09c3a1297b4d9e7caceaaa8\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/cb/e5/ac701e12d365a08917bf4c6171c0961bc880a8181359c66aa7\n",
            "Successfully built lime\n",
            "Installing collected packages: lime\n",
            "Successfully installed lime-0.2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43OV9pFiEmdI"
      },
      "source": [
        "<b>Loading required libraries</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFhuOwbrEmdJ"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "from aif360.datasets import GermanDataset\n",
        "from aif360.metrics import BinaryLabelDatasetMetric\n",
        "from aif360.metrics import ClassificationMetric\n",
        "from aif360.algorithms.inprocessing import MetaFairClassifier\n",
        "\n",
        "from aif360.datasets.lime_encoder import LimeEncoder\n",
        "\n",
        "import lime\n",
        "import lime.lime_tabular"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IK8WDunUEmdJ"
      },
      "source": [
        "<b>Loading the dataset</b>\n",
        "\n",
        "Here, we will load the <i><b>German credit data</b></i> in a format that is compatible with the use of the <i><b>AIF360 toolkit</b></i>. For this, you need to make use of the already implemented class of the toolkit `GermanDataset()`.\n",
        "\n",
        "Because the data available is encoded in a complex way, we provide you with the code to preprocess it, in the function `custom_preprocessing()`. We also provide you with an example on how to actually load the data using the `GermanDataset()` class, in `preproc_and_load_data_german()`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWQpGlcLEmdK"
      },
      "source": [
        "def preproc_and_load_data_german():\n",
        "    \"\"\"\n",
        "    Load and pre-process german credit dataset.\n",
        "    Args: -\n",
        "    Returns:\n",
        "        GermanDataset: An instance of GermanDataset with required pre-processing.\n",
        "    \"\"\"\n",
        "    def custom_preprocessing(df):\n",
        "        \"\"\" Custom pre-processing for German Credit Data\n",
        "        \"\"\"\n",
        "\n",
        "        def group_credit_hist(x):\n",
        "            if x in ['A30', 'A31', 'A32']:\n",
        "                return 'None/Paid'\n",
        "            elif x == 'A33':\n",
        "                return 'Delay'\n",
        "            elif x == 'A34':\n",
        "                return 'Other'\n",
        "            else:\n",
        "                return 'NA'\n",
        "\n",
        "        def group_employ(x):\n",
        "            if x == 'A71':\n",
        "                return 'Unemployed'\n",
        "            elif x in ['A72', 'A73']:\n",
        "                return '1-4 years'\n",
        "            elif x in ['A74', 'A75']:\n",
        "                return '4+ years'\n",
        "            else:\n",
        "                return 'NA'\n",
        "\n",
        "        def group_savings(x):\n",
        "            if x in ['A61', 'A62']:\n",
        "                return '<500'\n",
        "            elif x in ['A63', 'A64']:\n",
        "                return '500+'\n",
        "            elif x == 'A65':\n",
        "                return 'Unknown/None'\n",
        "            else:\n",
        "                return 'NA'\n",
        "\n",
        "        def group_status(x):\n",
        "            if x in ['A11', 'A12']:\n",
        "                return '<200'\n",
        "            elif x in ['A13']:\n",
        "                return '200+'\n",
        "            elif x == 'A14':\n",
        "                return 'None'\n",
        "            else:\n",
        "                return 'NA'\n",
        "        \n",
        "        def group_personal_status(x):\n",
        "            if x in ['A91']:\n",
        "                return 'divorced/separated'\n",
        "            elif x in ['A92']:\n",
        "                return 'divorced/separated/married'\n",
        "            elif x in ['A93', 'A95']:\n",
        "                return 'single'\n",
        "            elif x in ['A94']:\n",
        "                return 'married/widowed'\n",
        "            else:\n",
        "                return 'NA'\n",
        "        #print(df)\n",
        "        #print(df.shape)\n",
        "        #print(df.isnull().sum().sum())\n",
        "        #print(df.isin(['NA']).sum(axis=0))\n",
        "        status_map = {'A91': 1.0, 'A93': 1.0, 'A94': 1.0,\n",
        "                    'A92': 0.0, 'A95': 0.0}\n",
        "        \n",
        "        df['sex'] = df['personal_status'].replace(status_map)\n",
        "        \n",
        "\n",
        "        # group credit history, savings, and employment\n",
        "        df['credit_history'] = df['credit_history'].apply(lambda x: group_credit_hist(x))\n",
        "        df['savings'] = df['savings'].apply(lambda x: group_savings(x))\n",
        "        df['employment'] = df['employment'].apply(lambda x: group_employ(x))\n",
        "        #df['age'] = df['age'].apply(lambda x: np.float(x >= 26))\n",
        "        df['status'] = df['status'].apply(lambda x: group_status(x))\n",
        "        df['personal_status'] = df['personal_status'].apply(lambda x: group_personal_status(x))\n",
        "        #print(df.isin(['NA']).sum(axis=0))\n",
        "        \n",
        "        print(df)\n",
        "        df.to_csv(\"german_credit_data_processed_v2.csv\")\n",
        "        return df\n",
        "\n",
        "    # Feature partitions\n",
        "    XD_features = ['number_of_credits', 'telephone',\n",
        "                     'foreign_worker', 'people_liable_for', 'skill_level', 'credit_history', 'installment_plans', 'residence_since', 'property', 'other_debtors', 'purpose', 'savings', 'employment', 'sex', 'age', 'personal_status', 'month']\n",
        "    D_features = ['sex', 'age'] \n",
        "    Y_features = ['credit']\n",
        "    X_features = list(set(XD_features)-set(D_features))\n",
        "    categorical_features = ['installment_plans', 'telephone',\n",
        "                     'foreign_worker', 'skill_level', 'credit_history', 'property', \n",
        "                            'other_debtors', 'purpose', 'savings', 'employment', 'personal_status']\n",
        "\n",
        "    # privileged classes\n",
        "    all_privileged_classes = {\"sex\": [1.0],\n",
        "                              \"age\": lambda x: x > 25}\n",
        "\n",
        "    # protected attribute maps\n",
        "    all_protected_attribute_maps = {\"sex\": {1.0: 'Male', 0.0: 'Female'},\n",
        "                                    \"age\": {1.0: 'Old', 0.0: 'Young'}}\n",
        "\n",
        "    return GermanDataset(\n",
        "        label_name=Y_features[0],\n",
        "        favorable_classes=[1],\n",
        "        protected_attribute_names=D_features,\n",
        "        privileged_classes=[all_privileged_classes[x] for x in D_features],\n",
        "        instance_weights_name=None,\n",
        "        categorical_features=categorical_features,\n",
        "        features_to_keep=X_features+Y_features+D_features,\n",
        "        features_to_drop=[],\n",
        "        metadata={ 'label_maps': [{1.0: 'Good Credit', 2.0: 'Bad Credit'}],\n",
        "                   'protected_attribute_maps': [all_protected_attribute_maps[x]\n",
        "                                for x in D_features]},\n",
        "        custom_preprocessing=custom_preprocessing)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9KaI3_9EmdL"
      },
      "source": [
        "<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1MEmRvjEmdM"
      },
      "source": [
        "<H3>Step 2: Explore and familiarize with the dataset</H3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_IBf9xjEmdM"
      },
      "source": [
        "<b>Q1: Analyse the dataset and answer the following:</b> \n",
        "- What is the number of records, \n",
        "- What is the number of attributes present with the preprocessing we provided, and \n",
        "- What is the list of attribute names.\n",
        "- Are there missing values that could create biases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2msevC-kEmdM"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\">\n",
        "<b>Note:</b> If you encounted any errors in the following cell add the files \"german.doc\" and \"german.data\" to the folder <br>\n",
        "\"dist-packages/aif360/data/raw/german/\" under your python path you should get the same instructions in the error message.\n",
        "\n",
        "You can find the files in Brightspace or download them from: <br>\n",
        "https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data<br>\n",
        "https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.doc\n",
        "    </div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CJYOGJuEmdN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3522b5b2-f322-4584-f1b3-8e2565e8c17f"
      },
      "source": [
        "# Instanciating the German credit dataset\n",
        "dataset_gcredit = preproc_and_load_data_german()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    status  month credit_history purpose  ...  telephone foreign_worker credit  sex\n",
            "0     <200      6          Other     A43  ...       A192           A201      1  1.0\n",
            "1     <200     48      None/Paid     A43  ...       A191           A201      2  0.0\n",
            "2     None     12          Other     A46  ...       A191           A201      1  1.0\n",
            "3     <200     42      None/Paid     A42  ...       A191           A201      1  1.0\n",
            "4     <200     24          Delay     A40  ...       A191           A201      2  1.0\n",
            "..     ...    ...            ...     ...  ...        ...            ...    ...  ...\n",
            "995   None     12      None/Paid     A42  ...       A191           A201      1  0.0\n",
            "996   <200     30      None/Paid     A41  ...       A192           A201      1  1.0\n",
            "997   None     12      None/Paid     A43  ...       A191           A201      1  1.0\n",
            "998   <200     45      None/Paid     A43  ...       A192           A201      2  1.0\n",
            "999   <200     45          Other     A41  ...       A191           A201      1  1.0\n",
            "\n",
            "[1000 rows x 22 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUexEvEOEmdN"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "<b>Tip:</b> The documentation of \"AIF360 - German credit data\" dataset  can be found <a href=\"https://aif360.readthedocs.io/en/latest/modules/generated/aif360.datasets.GermanDataset.html\">[HERE]</a>. \n",
        "\n",
        "\n",
        "Take a look at documentation of AIF360 and use existing methods to explore the dataset instance how to access the features with:<br> `dataset_gcredit.features`. \n",
        "\n",
        "You are also free to transform the dataset into a pandas dataframe to extract the needed information.\n",
        "Use <br>\n",
        "    `pd_gdata = pd.DataFrame(dataset_gcredit.features, columns=dataset_gcredit.feature_names)` <br>\n",
        "    to create the pandas dataframe\n",
        "</div> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPk-GexgEmdR"
      },
      "source": [
        "- "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeC8sIAjEmdS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7557ea3e-738e-4d33-9c20-1293d4404a26"
      },
      "source": [
        "### Answer by writing the code in this cell (or create more cells if needed):###\n",
        "# Number of records:\n",
        "pd_gdata = pd.DataFrame(dataset_gcredit.features, columns=dataset_gcredit.feature_names)\n",
        "print('Number of records: \\n', pd_gdata.shape[0], '\\n')\n",
        "\n",
        "\n",
        "# Number of features:\n",
        "#print(pd_gdata.columns)\n",
        "print('Number of featurest using shape function: \\n', pd_gdata.shape[1], '\\n')\n",
        "# or\n",
        "print('Number of featurest using columns function: \\n', np.size(pd_gdata.columns), '\\n')\n",
        "\n",
        "\n",
        "# Feature names:\n",
        "#print('Feature names: ', pd_gdata.columns)\n",
        "print('Feature names: \\n', \"//* *//\".join(pd_gdata.columns), '\\n')\n",
        "\n",
        "\n",
        "#Number of missing values for each attribute\n",
        "print(\" \\nCount total NaN at each column in a DataFrame : \\n\\n\",\n",
        "      pd_gdata.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of records: \n",
            " 1000 \n",
            "\n",
            "Number of featurest using shape function: \n",
            " 47 \n",
            "\n",
            "Number of featurest using columns function: \n",
            " 47 \n",
            "\n",
            "Feature names: \n",
            " month//* *//residence_since//* *//age//* *//number_of_credits//* *//people_liable_for//* *//sex//* *//credit_history=Delay//* *//credit_history=None/Paid//* *//credit_history=Other//* *//purpose=A40//* *//purpose=A41//* *//purpose=A410//* *//purpose=A42//* *//purpose=A43//* *//purpose=A44//* *//purpose=A45//* *//purpose=A46//* *//purpose=A48//* *//purpose=A49//* *//savings=500+//* *//savings=<500//* *//savings=Unknown/None//* *//employment=1-4 years//* *//employment=4+ years//* *//employment=Unemployed//* *//personal_status=divorced/separated//* *//personal_status=divorced/separated/married//* *//personal_status=married/widowed//* *//personal_status=single//* *//other_debtors=A101//* *//other_debtors=A102//* *//other_debtors=A103//* *//property=A121//* *//property=A122//* *//property=A123//* *//property=A124//* *//installment_plans=A141//* *//installment_plans=A142//* *//installment_plans=A143//* *//skill_level=A171//* *//skill_level=A172//* *//skill_level=A173//* *//skill_level=A174//* *//telephone=A191//* *//telephone=A192//* *//foreign_worker=A201//* *//foreign_worker=A202 \n",
            "\n",
            " \n",
            "Count total NaN at each column in a DataFrame : \n",
            "\n",
            " month                                         0\n",
            "residence_since                               0\n",
            "age                                           0\n",
            "number_of_credits                             0\n",
            "people_liable_for                             0\n",
            "sex                                           0\n",
            "credit_history=Delay                          0\n",
            "credit_history=None/Paid                      0\n",
            "credit_history=Other                          0\n",
            "purpose=A40                                   0\n",
            "purpose=A41                                   0\n",
            "purpose=A410                                  0\n",
            "purpose=A42                                   0\n",
            "purpose=A43                                   0\n",
            "purpose=A44                                   0\n",
            "purpose=A45                                   0\n",
            "purpose=A46                                   0\n",
            "purpose=A48                                   0\n",
            "purpose=A49                                   0\n",
            "savings=500+                                  0\n",
            "savings=<500                                  0\n",
            "savings=Unknown/None                          0\n",
            "employment=1-4 years                          0\n",
            "employment=4+ years                           0\n",
            "employment=Unemployed                         0\n",
            "personal_status=divorced/separated            0\n",
            "personal_status=divorced/separated/married    0\n",
            "personal_status=married/widowed               0\n",
            "personal_status=single                        0\n",
            "other_debtors=A101                            0\n",
            "other_debtors=A102                            0\n",
            "other_debtors=A103                            0\n",
            "property=A121                                 0\n",
            "property=A122                                 0\n",
            "property=A123                                 0\n",
            "property=A124                                 0\n",
            "installment_plans=A141                        0\n",
            "installment_plans=A142                        0\n",
            "installment_plans=A143                        0\n",
            "skill_level=A171                              0\n",
            "skill_level=A172                              0\n",
            "skill_level=A173                              0\n",
            "skill_level=A174                              0\n",
            "telephone=A191                                0\n",
            "telephone=A192                                0\n",
            "foreign_worker=A201                           0\n",
            "foreign_worker=A202                           0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5Q0zG0OM8Nb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ba143a2-240f-438e-c95c-c7c409f666c9"
      },
      "source": [
        "dataset_gcredit\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               instance weights features  ...                     labels\n",
              "                                          ...                           \n",
              "                                   month  ... foreign_worker=A202       \n",
              "instance names                            ...                           \n",
              "0                           1.0      6.0  ...                 0.0    1.0\n",
              "1                           1.0     48.0  ...                 0.0    2.0\n",
              "2                           1.0     12.0  ...                 0.0    1.0\n",
              "3                           1.0     42.0  ...                 0.0    1.0\n",
              "4                           1.0     24.0  ...                 0.0    2.0\n",
              "...                         ...      ...  ...                 ...    ...\n",
              "995                         1.0     12.0  ...                 0.0    1.0\n",
              "996                         1.0     30.0  ...                 0.0    1.0\n",
              "997                         1.0     12.0  ...                 0.0    1.0\n",
              "998                         1.0     45.0  ...                 0.0    2.0\n",
              "999                         1.0     45.0  ...                 0.0    1.0\n",
              "\n",
              "[1000 rows x 49 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2k6fJbR9EmdT"
      },
      "source": [
        "<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZwzshxUEmdT"
      },
      "source": [
        "<H3>Step 3: Identify protected attributes and proxies</H3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXw1Cd63EmdU"
      },
      "source": [
        "<b>Q2: Identification of protected attributes</b>\n",
        "\n",
        "a) Study the dataset and its documentation and identify which attributes that might raise unfairness concerns and should be considered protected (according to the law). Explain, in your opinion, why are these attributes protected provide exaples of bias or unfaireness for each identified attribute. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQmT8CL7EmdU"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "<b>Tip:</b> \n",
        "Take a look at the following documents<br>\n",
        "<a href=\"https://rm.coe.int/discrimination-artificial-intelligence-and-algorithmic-decision-making/1680925d73\">(1) Discrimination, Artificial Intelligence, and Algorithmic Decision-Making (2018)</a><br>\n",
        "<a href=\"http://ec.europa.eu/social/BlobServlet?docId=1691&langId=en&usg=AOvVaw3vI30bO3jisairH2Z7-nSl\">(2) Age discrimination and European Law (2005)</a>. \n",
        "<div> \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtiBTaXfYBbs"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6erBT7pbTCr"
      },
      "source": [
        "\n",
        "The attributes that might raise unfairness concerns that should be protected according to law are \n",
        "\n",
        "1.   **Personal status** : Personal status as an attribute should be protected because, some algorithms can learn such that it can generalise a person's ability to repay based on their personal status   \n",
        "2. **Sex** : An attribute based on sex can lead to negative bias towards certain sexual identifications and unfairness against the communities who are historically unrecognised such as LGBTQ+ in conservative regions  and under-represented genders.\n",
        "3.   **Age in years**: There are very high possibilities that people in the early stages of career and post retirement will be discriminated in an unfair manner\n",
        "4.  **Foreign worker**: A person's national origin might affect the decision making process, which is not fair\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6K6agWaJEmdU"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlIz86u5EmdV"
      },
      "source": [
        "b) Study the dataset and its documentation and identify any further \"non-protect\" attributes that could cause  unfairenesses. Explain your reasoning. provide examples of bias or unfairenesse related to each attribut."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWdFZmi6EmdV"
      },
      "source": [
        "1. **Skill level**: A person's skill level is not a very sensitive information to be protected. But at the same time it can cause bias towards highly skilled people and officers, which will be unfair to the unskilled people and self employed\n",
        "2. **Housing type**: This is not a protected attribute, but at the same time it can cause unfairness towards people who do not have house of their own, even if they have other means of investments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7STqJtdlEmdV"
      },
      "source": [
        "<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEg8eWGKEmdV"
      },
      "source": [
        "<b>Q3:  Identification of \"spurious\" proxies</b>\n",
        "\n",
        "a) Find the proxies for the attribute \"sex\".\n",
        "\n",
        "b) Find proxies for one additional protected attribut you identified in Q2-a.\n",
        "\n",
        "c) In your opinion, why do we want to identify proxies for protected attributes in a dataset? How should you handle the proxies?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHnlOz9Invl8",
        "outputId": "ebc1c68e-bef7-41c1-e4b9-0875c6304561"
      },
      "source": [
        "a=pd_gdata.corrwith(pd_gdata.sex)\n",
        "a.sort_values(0,ascending=False)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sex                                           1.000000\n",
              "personal_status=single                        0.738036\n",
              "age                                           0.254083\n",
              "personal_status=married/widowed               0.213357\n",
              "people_liable_for                             0.203431\n",
              "employment=4+ years                           0.167724\n",
              "personal_status=divorced/separated            0.153773\n",
              "number_of_credits                             0.094260\n",
              "property=A124                                 0.088297\n",
              "credit_history=Delay                          0.086092\n",
              "month                                         0.081432\n",
              "purpose=A49                                   0.080875\n",
              "telephone=A192                                0.075966\n",
              "purpose=A41                                   0.056410\n",
              "credit_history=Other                          0.056200\n",
              "skill_level=A174                              0.054070\n",
              "foreign_worker=A202                           0.051202\n",
              "installment_plans=A142                        0.046689\n",
              "savings=Unknown/None                          0.043225\n",
              "purpose=A45                                   0.026828\n",
              "installment_plans=A141                        0.019313\n",
              "purpose=A410                                  0.014297\n",
              "purpose=A40                                   0.012972\n",
              "other_debtors=A103                            0.010907\n",
              "purpose=A43                                   0.008668\n",
              "other_debtors=A102                            0.007742\n",
              "savings=500+                                 -0.004061\n",
              "purpose=A48                                  -0.004808\n",
              "property=A121                                -0.007592\n",
              "skill_level=A173                             -0.007613\n",
              "skill_level=A172                             -0.010811\n",
              "other_debtors=A101                           -0.013624\n",
              "residence_since                              -0.013818\n",
              "property=A123                                -0.027915\n",
              "savings=<500                                 -0.033886\n",
              "employment=Unemployed                        -0.033891\n",
              "property=A122                                -0.036266\n",
              "installment_plans=A143                       -0.042565\n",
              "purpose=A44                                  -0.045275\n",
              "foreign_worker=A201                          -0.051202\n",
              "purpose=A46                                  -0.054565\n",
              "telephone=A191                               -0.075966\n",
              "skill_level=A171                             -0.076356\n",
              "purpose=A42                                  -0.100467\n",
              "credit_history=None/Paid                     -0.102893\n",
              "employment=1-4 years                         -0.149617\n",
              "personal_status=divorced/separated/married   -1.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNRPArj0vAVQ",
        "outputId": "7f732601-cf74-4042-9cc7-3e7f14dfed5d"
      },
      "source": [
        "a=pd_gdata.corrwith(pd_gdata.age)\n",
        "a.sort_values(0,ascending=False)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age                                           1.000000\n",
              "sex                                           0.254083\n",
              "personal_status=single                        0.246460\n",
              "skill_level=A174                              0.165966\n",
              "employment=4+ years                           0.165577\n",
              "people_liable_for                             0.165169\n",
              "telephone=A192                                0.164986\n",
              "number_of_credits                             0.138322\n",
              "credit_history=Other                          0.126966\n",
              "property=A124                                 0.121892\n",
              "personal_status=divorced/separated            0.087719\n",
              "credit_history=Delay                          0.087460\n",
              "purpose=A40                                   0.075020\n",
              "purpose=A49                                   0.072607\n",
              "foreign_worker=A202                           0.054422\n",
              "purpose=A410                                  0.053376\n",
              "installment_plans=A141                        0.047231\n",
              "purpose=A41                                   0.046711\n",
              "savings=Unknown/None                          0.044631\n",
              "savings=500+                                  0.033189\n",
              "employment=Unemployed                         0.029385\n",
              "purpose=A46                                   0.029240\n",
              "other_debtors=A101                            0.020450\n",
              "purpose=A48                                   0.019164\n",
              "residence_since                               0.012824\n",
              "month                                         0.007946\n",
              "installment_plans=A142                       -0.000843\n",
              "other_debtors=A103                           -0.012859\n",
              "skill_level=A171                             -0.014250\n",
              "other_debtors=A102                           -0.015555\n",
              "property=A122                                -0.017634\n",
              "skill_level=A172                             -0.025491\n",
              "purpose=A45                                  -0.031628\n",
              "property=A121                                -0.036369\n",
              "purpose=A44                                  -0.040266\n",
              "installment_plans=A143                       -0.041534\n",
              "property=A123                                -0.042870\n",
              "foreign_worker=A201                          -0.054422\n",
              "savings=<500                                 -0.060762\n",
              "purpose=A43                                  -0.061314\n",
              "personal_status=married/widowed              -0.083962\n",
              "skill_level=A173                             -0.096619\n",
              "purpose=A42                                  -0.116589\n",
              "telephone=A191                               -0.164986\n",
              "credit_history=None/Paid                     -0.170014\n",
              "employment=1-4 years                         -0.178019\n",
              "personal_status=divorced/separated/married   -0.254083\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6H3tPagEmdV"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "<b> Tip: </b>A proxy attribute <i>Ap</i>  is an attribute that has a similar distribution as another attribute <i>Ax</i>, so having access to the proxy attribute <i>Ap</i> provides a good knowledge of the other attribute <i>Ax</i>. For instance, in the US the zipcode is a powerful proxy for race and education, the zipcode combined with websites visited is an even more powerful proxy, names in certain languages are strong proxies for gender, etc.<br>\n",
        "\n",
        "The simplest way to identify proxy attributes for a protected attribute <i>Ax</i> is to compute the correlation of <i>Ax</i>  with each other attributes in the dataset. The higher the corrolation the higher the likelihood an attribute is a proxy of <i>Ax</i> <br>\n",
        "\n",
        "You can use the `corr()` function of the pandas library to compute the correlation between two attributes\n",
        "</div> \n",
        "\n",
        "\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHKFI0p_voH3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRpOVH8Dt3I8"
      },
      "source": [
        "**Answer**:\n",
        " \n",
        "\n",
        "a) A person's personal status is identified to be a possible proxy for person's 'sex' attribute. Age is a possible proxy attribute\n",
        "\n",
        "\n",
        " b) Similarly, sex and personal status can be used as a proxy for age attribute\n",
        "\n",
        "\n",
        " c) We want to identify proxies for protected attributes in a dataset, because these proxies can indirectly influence the algorithm in such a way that even after removing the protected attributes in training and decision making, these proxies will make sure that bias and unfairness are still in the system. We should handle the proxy attributes by improving data collection at the source removing the proxy characteristics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWhGuIzNEmdW"
      },
      "source": [
        "<br>\n",
        "<b>Q4: Data skews and Representation biases</b>\n",
        "\n",
        "a) Is the dataset we are working with representative of the German population with regard to age. <br>\n",
        "Add any needed code or analysis to briefely justify your answer<br>\n",
        "\n",
        "b) Is the dataset we are working with representative of the German population with regard to gender. <br>\n",
        "Add any needed code or analysis to briefely justify your answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3eOfRUJEmdW"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "<b> Tip: </b> You can find demographic information from Wikipedia <a href=https://en.wikipedia.org/wiki/Demographics_of_Germany>[Here]</a>\n",
        "    \n",
        "Go to section <b><i>Demographic statistics</i></b> take a closer look at the most racent  <b><i>Age structure</i></b> data (it should be from 2018). Use this data to build a distribution of german population across age, then across gender and compare it to the distributions from <b><i>the German credit data</i></b> we are working with.\n",
        "\n",
        "It is up to you how you want to justify your answer, however using visualizations will provide more points (i.e., plots and diagram)\n",
        "</div>\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bzvLTjyEmdW"
      },
      "source": [
        "# Answer with the code here \n",
        "# No code is required however it will make your reasening clearer to the assessor \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duagISXQEmdX"
      },
      "source": [
        "-"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oE6enRTEmdX"
      },
      "source": [
        "<b>Q5: Data skews</b> \n",
        "\n",
        "Is there a skew towards certain groups:<br>\n",
        "a) Analyse the dataset, and report the numbers of male / female with bad/good credit. Do the same for \"old\" / \" young\" people in the datset. Normalize these numbers respectively over the total number of males/females, \"old\"/\"young\" for a fair comparison. For that, you can consider having 50 individuals for each of these groups.\n",
        "\n",
        "b) Brieflt describe your findings and explain the impacts (on faireness) of using this dataset as training data (if any)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fq0De7-EmdX"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "<b> Tip: </b> We provide a function for Normalised count per attribut and lable you are free to use it or implement your own method \n",
        "    \n",
        "`getNormalizedCount()`\n",
        "</div>\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjAnK7WTEmdX"
      },
      "source": [
        "# Normalised count per attribut and lable \n",
        "def getNormalizedCount(pd_train_data, protected_attribute, label):\n",
        "    unnormalized_count = pd_train_data[[protected_attribute, label]].value_counts()\n",
        "    counts = {}\n",
        "    for attribute_value in pd_train_data[[protected_attribute]].value_counts().keys():\n",
        "        counts[attribute_value[0]] = pd_train_data[[protected_attribute]].value_counts()[attribute_value]\n",
        "    normalized_count = unnormalized_count[:]\n",
        "    for attribute_value, credit_value in pd_train_data[[protected_attribute, label]].value_counts().keys():\n",
        "        normalized_count[attribute_value, credit_value] = normalized_count[attribute_value, credit_value] * (50 / counts[attribute_value])\n",
        "    return normalized_count\n",
        "\n",
        "# add the credit labels to the data set.\n",
        "pd_gdata[\"credit\"] = dataset_gcredit.labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkYeYiAhEmdY"
      },
      "source": [
        "### YOUR ANSWER HERE ###\n",
        "# ADD code here to print the AGE-CREDIT distribution\n",
        "\n",
        "\n",
        "# ADD code here to print the SEX-CREDIT distribution\n",
        "\n",
        "\n",
        "# ADD code here to visualise the results for both you can use stacked bar plots from pandas toolkit\n",
        "#<your dataframe>.size().unstack().plot(kind='bar', stacked=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUpGS-SyEmdY"
      },
      "source": [
        "-"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWmlCsqiEmdY"
      },
      "source": [
        "<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c_jPl3qEmdZ"
      },
      "source": [
        "<H3> Step 4: In-Prosessing Biases </H3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bsWS8OWEmdZ"
      },
      "source": [
        "<b>Q6: We will apply in-processing mitigation technique to alliviate the <i>age</i> biase in the German credit data</b>\n",
        "\n",
        "a) Set the privilege and unprivilaged age group based on the findings of question Q5-a (answer in the text then add the variables 0 or 1 to the code below). Provide a very brief justification for your answer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0fnUdnTEmdZ"
      },
      "source": [
        "-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRon1mP0Emda"
      },
      "source": [
        "# Add the code for question a) here\n",
        "# code = 1: is old above 25\n",
        "# code = 0: is young under 25\n",
        "\n",
        "privileged_code = #add the write code here\n",
        "unprivileged_code = #add the write code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r24lRpiuEmda"
      },
      "source": [
        "# We start by defining the privilaged and unprivileged \n",
        "privileged_groups = [{'age': privileged_code}] \n",
        "unprivileged_groups = [{'age': unprivileged_code}] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oU9jkw40Emda"
      },
      "source": [
        "<b>Preparation for training a classifier.</b><br>\n",
        "We will  divide the dataset into a training and a test subsets.\n",
        "We define them respectively as 70% and 30% of the whole data.\n",
        "We will use the following code to do so."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CA5h9sDxEmdb"
      },
      "source": [
        "dataset_gcredit_train, dataset_gcredit_test = \\\n",
        "    dataset_gcredit.split([0.7], shuffle=True, seed=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "try4K33sEmdb"
      },
      "source": [
        "<b>Faireness before mitigation</b><br>\n",
        "Below we are using several faireness metrics from AIF360 toolkint to evaluate fairenesse metrics before appling the inprocessing mitigation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GmqeybPEmdb"
      },
      "source": [
        "metric_orig_train = BinaryLabelDatasetMetric(dataset_gcredit_train, \n",
        "                                             unprivileged_groups=unprivileged_groups,\n",
        "                                             privileged_groups=privileged_groups)\n",
        "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = {:.3f}\".format(metric_orig_train.mean_difference()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYlevFWwEmdb"
      },
      "source": [
        "Get classifier without fairness constraints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puMJxJEXEmdc"
      },
      "source": [
        "biased_model = MetaFairClassifier(tau=0, sensitive_attr=\"sex\", type=\"fdr\").fit(dataset_gcredit_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdXwD5qYEmdc"
      },
      "source": [
        "Apply the unconstrained model to test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1g8iu6xEmdc"
      },
      "source": [
        "dataset_bias_test = biased_model.predict(dataset_gcredit_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gn62vkdREmdc"
      },
      "source": [
        "Build and test the \"biased\" classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQWRoNKaEmdd"
      },
      "source": [
        "classified_metric_bias_test = ClassificationMetric(dataset_gcredit_test, dataset_bias_test,\n",
        "                                                   unprivileged_groups=unprivileged_groups,\n",
        "                                                   privileged_groups=privileged_groups)\n",
        "print(\"Test set: Classification accuracy = {:.3f}\".format(classified_metric_bias_test.accuracy()))\n",
        "TPR = classified_metric_bias_test.true_positive_rate()\n",
        "TNR = classified_metric_bias_test.true_negative_rate()\n",
        "bal_acc_bias_test = 0.5*(TPR+TNR)\n",
        "print(\"Test set: Balanced classification accuracy = {:.3f}\".format(bal_acc_bias_test))\n",
        "print(\"Test set: Disparate impact = {:.3f}\".format(classified_metric_bias_test.disparate_impact()))\n",
        "fdr = classified_metric_bias_test.false_discovery_rate_ratio()\n",
        "fdr = min(fdr, 1/fdr)\n",
        "print(\"Test set: False discovery rate ratio = {:.3f}\".format(fdr))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXo1Qz4vEmdd"
      },
      "source": [
        "<br>\n",
        "<b> Q6 -</b>\n",
        "b) Run the code above and explain the results: briefly describe each metric and the interpretation of the values.\n",
        "\n",
        "Metrics:<br>\n",
        "- Difference in mean outcomes between unprivileged and privileged groups\n",
        "- Classification accuracy\n",
        "- Balanced classification accuracy\n",
        "- Disparate impact\n",
        "- False discovery rate ratio\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CFhMRP2Emdd"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "<b> Tip: </b> Make use of the documentation of <a href=https://aif360.readthedocs.io/en/latest/index.html><b>AIF360</b></a>, and your own search to understaind the metrics and to be able to interpret them.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sr816St2Emdd"
      },
      "source": [
        "-"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2KVS07NEmde"
      },
      "source": [
        "<b> Train a debiased classifier </b><br>\n",
        "In the following we will apply an in-processing debiasin technique <b><i>\"Meta-Algorithm for fair classification\"</i></b>. This debiesing technique operates with a faireness constraint i.e., by optimising for faireness metrics. You can read more about it <a href=https://arxiv.org/pdf/1806.06055.pdf>[HERE]</a><br>\n",
        "For this example we will to optimize for the <i><b> the fals discovery rate (fdr)</b></i> and sensitive attribute <i><b> age </b></i>\n",
        "    \n",
        "Apply the debiased model to training data and train the <b><i>\"debiased\"</i></b> classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-GR0TINEmde"
      },
      "source": [
        "debiased_model = MetaFairClassifier(tau=0.7, sensitive_attr=\"age\", type=\"fdr\").fit(dataset_gcredit_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ex2rOFDEmde"
      },
      "source": [
        "Apply the debiased classifier to test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJwMXrq9Emdf"
      },
      "source": [
        "dataset_debiasing_test = debiased_model.predict(dataset_gcredit_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-4QzpLHEmdf"
      },
      "source": [
        "Compute the same faireness metrics for the <b><i>\"debiased\"</i></b> data and classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AaR5Ou3Emdh"
      },
      "source": [
        "metric_dataset_debiasing_test = BinaryLabelDatasetMetric(dataset_debiasing_test, \n",
        "                                             unprivileged_groups=unprivileged_groups,\n",
        "                                             privileged_groups=privileged_groups)\n",
        "\n",
        "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = {:.3f}\".format(metric_dataset_debiasing_test.mean_difference()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptVr1tF1Emdh"
      },
      "source": [
        "classified_metric_debiasing_test = ClassificationMetric(dataset_gcredit_test, \n",
        "                                                 dataset_debiasing_test,\n",
        "                                                 unprivileged_groups=unprivileged_groups,\n",
        "                                                 privileged_groups=privileged_groups)\n",
        "print(\"Test set: Classification accuracy = {:.3f}\".format(classified_metric_debiasing_test.accuracy()))\n",
        "TPR = classified_metric_debiasing_test.true_positive_rate()\n",
        "TNR = classified_metric_debiasing_test.true_negative_rate()\n",
        "bal_acc_debiasing_test = 0.5*(TPR+TNR)\n",
        "print(\"Test set: Balanced classification accuracy = {:.3f}\".format(bal_acc_debiasing_test))\n",
        "print(\"Test set: Disparate impact = {:.3f}\".format(classified_metric_debiasing_test.disparate_impact()))\n",
        "fdr = classified_metric_debiasing_test.false_discovery_rate_ratio()\n",
        "fdr = min(fdr, 1/fdr)\n",
        "print(\"Test set: False discovery rate ratio = {:.3f}\".format(fdr))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tccG8pAAEmdi"
      },
      "source": [
        "<br>\n",
        "<b> Q6 -</b>\n",
        "c) Run the code above and compare the results between the <b><i>\"debiased\"</i></b> and the <b><i>\"biased\"</i></b> classifiers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGu-FjFzEmdi"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "<b> Tip: </b> Focus on <b>FDR</b>, <b>Accuracy</b> and <b>Difference in mean outcomes</b>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbPphkSGEmdj"
      },
      "source": [
        "-"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeDitJSpEmdj"
      },
      "source": [
        "<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiyLPvZoEmdj"
      },
      "source": [
        "<H2> Part III. Explainability</H2>\n",
        "<i>LO-4. Compare different implementations of fairness metrics and unfairness mitigation approaches.  \n",
        "</i>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9R0AhkTEmdj"
      },
      "source": [
        "In this last part we will use the same scenario from Part II. To explore LIME Local Interpretable Model-Agnostic Explanations. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_E9hOvFEmdk"
      },
      "source": [
        "#Train model on german credit data dataset\n",
        "\n",
        "dataset = dataset_gcredit_train  # data to train on\n",
        "\n",
        "scale = StandardScaler().fit(dataset.features)   # remember the scale\n",
        "\n",
        "model = LogisticRegression()        # model to learn\n",
        "\n",
        "X_train = scale.transform(dataset.features)      #apply the scale\n",
        "y_train = dataset.labels.ravel()\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train, sample_weight=dataset.instance_weights)\n",
        "\n",
        "#save model\n",
        "lr_orig = model\n",
        "lr_scale_orig = scale"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzzVpXu6Emdk"
      },
      "source": [
        "#Test model on given dataset and find threshold for best balanced accuracy\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "thresh_arr = np.linspace(0.01, 0.5, 50)\n",
        "\n",
        "scale = lr_scale_orig\n",
        "\n",
        "model = lr_orig                  #model to test\n",
        "dataset = dataset_gcredit_test        #data to test on\n",
        "\n",
        "X_test = scale.transform(dataset.features)   #apply the same scale as applied to the training data\n",
        "y_test = dataset.labels.ravel()\n",
        "y_test_pred_prob = model.predict_proba(X_test)\n",
        "\n",
        "\n",
        "bal_acc_arr = []\n",
        "disp_imp_arr = []\n",
        "avg_odds_diff_arr = []\n",
        "    \n",
        "for thresh in tqdm(thresh_arr):\n",
        "    y_test_pred = (y_test_pred_prob[:,1] > thresh).astype(np.double)\n",
        "\n",
        "    dataset_pred = dataset.copy()\n",
        "    dataset_pred.labels = y_test_pred\n",
        "\n",
        "    classified_metric = ClassificationMetric(dataset, \n",
        "                                                 dataset_pred,\n",
        "                                                 unprivileged_groups=unprivileged_groups,\n",
        "                                                 privileged_groups=privileged_groups)\n",
        "    metric_pred = BinaryLabelDatasetMetric(dataset_pred,\n",
        "                                                 unprivileged_groups=unprivileged_groups,\n",
        "                                                 privileged_groups=privileged_groups)\n",
        "    \n",
        "    TPR = classified_metric.true_positive_rate()\n",
        "    TNR = classified_metric.true_negative_rate()\n",
        "    bal_acc = 0.5*(TPR+TNR)\n",
        "    \n",
        "    acc = accuracy_score(y_true=dataset.labels,\n",
        "                            y_pred=dataset_pred.labels)\n",
        "    bal_acc_arr.append(bal_acc)\n",
        "    avg_odds_diff_arr.append(classified_metric.average_odds_difference())\n",
        "    disp_imp_arr.append(metric_pred.disparate_impact())\n",
        "    \n",
        "thresh_arr_best_ind = np.where(bal_acc_arr == np.max(bal_acc_arr))[0][0]\n",
        "thresh_arr_best = np.array(thresh_arr)[thresh_arr_best_ind]\n",
        "\n",
        "best_bal_acc = bal_acc_arr[thresh_arr_best_ind]\n",
        "disp_imp_at_best_bal_acc = np.abs(1.0-np.array(disp_imp_arr))[thresh_arr_best_ind]\n",
        "\n",
        "avg_odds_diff_at_best_bal_acc = avg_odds_diff_arr[thresh_arr_best_ind]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WU17xQI8Emdk"
      },
      "source": [
        "limeData = LimeEncoder().fit(dataset_gcredit_train)\n",
        "s_train = limeData.transform(dataset_gcredit_train.features)\n",
        "s_test = limeData.transform(dataset_gcredit_test.features)\n",
        "\n",
        "scale = lr_scale_orig\n",
        "\n",
        "model = lr_orig                  #model to test\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "explainer = lime.lime_tabular.LimeTabularExplainer(s_train ,class_names=limeData.s_class_names, \n",
        "                                                   feature_names = limeData.s_feature_names,\n",
        "                                                   categorical_features=limeData.s_categorical_features, \n",
        "                                                   categorical_names=limeData.s_categorical_names, \n",
        "                                                   kernel_width=3, verbose=False,discretize_continuous=True)\n",
        "\n",
        "s_predict_fn = lambda x: model.predict_proba(scale.transform(limeData.inverse_transform(x)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oh5RtkVAEmdl"
      },
      "source": [
        "<br>\n",
        "<b>Q7: Using LIME </b> <br>\n",
        "a) Provide a short definition of LIME and what it is used for. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47DY3ry7Emdl"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "<b> Tip: </b> Information about LIME can be found <a href=https://arxiv.org/pdf/1602.04938.pdf> [HERE] </a>\n",
        "</div>\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0Olg7sSEmdl"
      },
      "source": [
        "-"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLiHN0aGEmdl"
      },
      "source": [
        "<b>Q7 - </b>\n",
        "b) Select two loan applications form the test data set (One classified as \"Good Credit\" and one \"Bad Credit\"). Get the decision explaned by Lime. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbG3BY8-Emdl"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "<b> Tip: </b>Use the following code to explain the classifier decision and print/plot the results from LIME\n",
        "\n",
        "`i = # the index of the test data entry goes here\n",
        "exp = explainer.explain_instance(s_test[i], s_predict_fn, num_features=5)\n",
        "exp.as_pyplot_figure()\n",
        "print(\"        Actual label: \" + str(dataset_gcredit_test.labels[i]))`\n",
        "\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9cDRzwGEmdm"
      },
      "source": [
        "# Good Credit explanation\n",
        "# Answer with the code here\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZISk3sEeEmdm"
      },
      "source": [
        "# Bad Credit explanation\n",
        "# Answer with the code here\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3SDLM3UEmdm"
      },
      "source": [
        "<b>Q7 - </b>\n",
        "c) Describe and explaine the results from lime for each of the decisions (Output of Q7-b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdZB8RTDEmdn"
      },
      "source": [
        "- Explain a \"Bad Credit\" decision explanation here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MphT42F3Emdn"
      },
      "source": [
        "- Explain a \"Good Credit\" decision explanation here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf30u_wIEmdn"
      },
      "source": [
        "<H3> --------- And of the assignment ---------</H3><br>\n",
        "<i>We hope that you enjoyed this lecture.<br> Nadia & Ibo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfwsrCN3Emdn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}